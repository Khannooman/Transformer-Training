Epoch 1 / 10:   0%|                                                         | 0/1000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/nooman/Documents/Transformer-Training/training.py", line 23, in <module>
    setup_training(data_dir, config)
  File "/home/nooman/Documents/Transformer-Training/training.py", line 16, in setup_training
    trainer.train(train_loader, val_loader)
  File "/home/nooman/Documents/Transformer-Training/train.py", line 142, in train
    outputs = self.model(**batch)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1665, in forward
    outputs = self.bert(
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 1078, in forward
    embedding_output = self.embeddings(
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py", line 211, in forward
    inputs_embeds = self.word_embeddings(input_ids)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/home/nooman/Documents/Transformer-Training/env/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
