Epoch 1 / 10:   0%|                                                         | 0/1000 [00:00<?, ?it/s]
SequenceClassifierOutput(loss=None, logits=tensor([[-0.8073, -0.7242,  1.8775],
        [-0.4963, -0.6132,  1.4516],
        [ 0.3066, -0.8375,  1.0699],
        [-0.9434, -0.0568,  1.5142],
        [ 0.2444, -1.0907,  1.2721],
        [-0.3389, -0.9813,  1.6962],
        [-0.5679, -0.4204,  1.7242],
        [-0.0856, -1.6240,  2.1606],
        [-0.0959, -0.8348,  1.7306],
        [ 0.4689, -1.2701,  1.5004],
        [-0.1441, -1.1404,  1.7678],
        [ 0.2326, -1.0738,  1.4419],
        [-0.3514, -0.8630,  2.0812],
        [-0.5215, -0.7171,  1.8789],
        [-0.8499, -0.1503,  1.8697],
        [-0.1427, -0.4855,  1.6028],
        [-0.5056, -0.5311,  2.0167],
        [-0.5110, -0.6822,  1.4452],
        [ 0.3478, -1.3103,  1.6112],
        [-0.3372, -0.1397, -0.3418],
        [-0.3396, -1.1140,  1.8724],
        [-0.4770, -0.5659,  1.5654],
        [ 0.2122, -0.3704,  0.5144],
        [-0.2058, -0.2905,  1.6259],
        [-0.4601, -0.3038,  1.0120],
        [-0.3780, -0.5700,  1.7231],
        [-0.0503, -1.1525,  1.6927],
        [-0.4866, -1.1227,  2.1600],
        [-0.3592, -0.5901,  1.4738],
        [-0.4053, -0.4551,  1.9239],
        [ 0.1464, -0.7091,  0.9556],
        [ 0.1687, -0.7397,  0.5782],
        [-0.5026, -1.0647,  1.3817],
        [-0.2947, -0.3119,  1.1986],
        [-0.1370, -1.2390,  1.1266],
        [-0.0852, -0.9062,  1.5016],
        [-0.1378, -0.4248, -0.0793],
        [ 0.6436, -1.6050,  0.7770],
        [-0.1047, -0.3893,  0.7991],
        [-0.5392,  1.2187, -0.5061],
        [-0.5945, -0.2214,  1.5053],
        [ 0.0048,  0.0358,  1.0862],
        [-0.9647,  0.2947,  1.4833],
        [-0.4251,  0.3631,  0.9543],
        [-0.5515, -0.4935,  1.6304],
        [-0.0587, -0.7409,  1.5506],
        [-0.6027,  0.5220,  0.9531],
        [-0.0932, -0.6381,  1.4955],
        [ 0.5611, -1.0281,  0.1339],
        [ 0.0360,  0.0133, -0.0335],
        [ 0.3873, -1.1318,  0.4965],
        [-0.6137,  0.8111,  0.9742],
        [-1.2914,  1.4129,  0.2537],
        [-1.0385,  0.7435,  0.9599],
        [-0.0715,  0.3884, -0.4062],
        [-1.1101,  0.8794,  1.0363],
        [-1.1865,  1.1642,  1.0151],
        [-1.4182,  0.8914,  1.4270],
        [-1.1808,  1.1137,  0.7889],
        [-1.2466,  0.8021,  1.0311],
        [-1.2760,  1.1890,  0.7892],
        [-1.2629,  0.6829,  1.5164],
        [-1.2317,  1.0341,  1.1042],
        [-1.4266,  1.0742,  1.1914],
        [-1.4301,  1.3267,  0.9240],
        [-1.2831,  0.6591,  1.3503],
        [-1.0805,  0.6257,  1.4048],
        [-1.0435,  0.7919,  0.9338],
        [-1.2496,  1.0637,  0.9039],
        [-1.1147,  0.7313,  1.2188],
        [-1.1899,  0.5474,  1.5604],
        [-1.0468,  0.8543,  1.0302],
        [-1.1100,  0.8494,  1.4292],
        [-0.8537,  0.7095,  1.2667],
        [-1.2704,  0.7557,  1.0712],
        [-1.2056,  0.7078,  1.4960],
        [-1.1559,  0.9887,  1.0586],
        [-1.3201,  0.9373,  1.1947],
        [-1.1896,  0.6133,  1.1274],
        [-1.4190,  0.8926,  1.1554],
        [-1.2861,  0.3584,  1.2727],
        [-1.1405,  0.5300,  0.9695],
        [-1.2168,  0.9383,  1.1002],
        [-1.2928,  1.2219,  0.8787],
        [-1.2225,  0.8813,  1.1067],
        [-1.2911,  0.8945,  1.2072],
        [-1.0647,  0.9191,  1.0111],
        [-1.2364,  1.1885,  1.0475],
        [-1.1462,  0.8274,  1.1035],
        [-1.1701,  0.8245,  0.6609],
        [-1.2917,  1.0209,  1.1489],
        [-1.2271,  0.6931,  1.3979],
        [-1.1404,  0.8315,  1.0518],
        [-1.2240,  0.8938,  0.9054],
        [-1.3296,  0.6681,  1.1658],
        [-1.1879,  0.7475,  1.2839],
        [-1.1378,  0.5496,  1.4679],
        [-1.1372,  0.9212,  1.0474],
        [-1.1027,  1.1307,  1.2821],
        [-1.2745,  0.9147,  1.2972],
        [-1.2541,  0.9363,  0.9319],
        [-1.1035,  0.9795,  0.7229],
        [-1.0430,  0.9345,  0.7868],
        [-1.2296,  0.9522,  1.1470],
        [-1.3121,  1.0424,  0.9199],
        [-0.9312,  0.7584,  0.9265],
        [-1.0977,  0.7212,  1.3425],
        [-1.0409,  0.8791,  1.3201],
        [-1.2995,  1.1953,  0.7604],
        [-1.2766,  1.1433,  1.0710],
        [-1.3073,  0.7101,  1.1647],
        [-1.1234,  0.8684,  1.0630],
        [-1.0468,  0.8305,  1.0043],
        [-1.1661,  1.2851,  1.3746],
        [-1.1207,  0.7546,  1.1411],
        [-1.2445,  1.0796,  1.1950],
        [-1.2107,  1.0146,  0.8356],
        [-1.3080,  1.0644,  0.8952],
        [-1.2534,  0.9815,  0.9358],
        [-1.0666,  1.0518,  0.7857],
        [-1.4915,  0.8450,  1.2396],
        [-1.1884,  0.8620,  0.9415],
        [-1.1233,  0.6821,  1.3362],
        [-1.0685,  0.6345,  1.5168],
        [-1.1965,  1.1167,  1.3098],
        [-1.0993,  0.7574,  1.0827],
        [-1.2231,  0.8769,  1.0337],
        [-1.0126,  0.8346,  1.0595]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)
Traceback (most recent call last):
  File "/home/nooman/Documents/Transformer-Training/training.py", line 23, in <module>
    setup_training(data_dir, config)
  File "/home/nooman/Documents/Transformer-Training/training.py", line 16, in setup_training
    trainer.train(train_loader, val_loader)
  File "/home/nooman/Documents/Transformer-Training/train.py", line 143, in train
    loss.backward()
AttributeError: 'NoneType' object has no attribute 'backward'
