Epoch 1 / 10:   0%|                                                         | 0/1000 [00:00<?, ?it/s]
tensor([1, 2, 0, 4, 4, 1, 5, 3, 0, 4, 3, 4, 4, 1, 0, 0])
SequenceClassifierOutput(loss=None, logits=tensor([[-0.7360, -0.7927,  2.0367],
        [ 0.0859, -0.7893,  0.8539],
        [ 0.0202, -0.3718,  0.7885],
        [ 0.2316, -0.6785,  0.5405],
        [-0.5683, -0.3612,  2.0186],
        [-0.1654, -0.9754,  1.6781],
        [ 0.8241, -1.0650,  0.7307],
        [-0.2408, -0.0530,  1.0913],
        [-0.7858, -0.4413,  1.9200],
        [ 0.0537, -0.9154,  1.6676],
        [-0.1566, -0.3715,  0.9792],
        [-0.5836, -1.1115,  1.8818],
        [ 0.2597, -1.3322,  1.4299],
        [-0.5962, -0.0519,  0.7948],
        [-0.4983, -0.2118,  1.3221],
        [-0.1193, -0.6746,  1.4815],
        [-0.0408, -0.4594,  1.1428],
        [ 0.3747, -1.7460,  1.5904],
        [-0.1854, -0.3764,  0.7135],
        [-0.2959, -1.2247,  2.1338],
        [ 0.0868, -0.3200,  0.9933],
        [-0.7676,  0.1569,  1.0131],
        [ 0.3467, -0.9189,  0.3099],
        [ 0.8678, -0.3733, -0.8928],
        [-0.0538, -0.2187,  0.0987],
        [ 0.5433, -1.0969,  0.3061],
        [-0.3105, -0.8112,  1.0368],
        [-0.7396,  0.1460,  1.1287],
        [ 0.2564, -0.5286,  0.9063],
        [ 0.5634, -0.9809,  0.3415],
        [-0.1740, -0.7193,  1.6130],
        [-1.1886,  0.7867,  0.6414],
        [-0.0561, -0.6651, -0.3547],
        [-0.3226, -0.8591,  0.6010],
        [-0.3128, -1.0795,  1.4323],
        [-0.0946, -0.2639,  1.1958],
        [-1.0569,  0.1755,  1.5502],
        [-0.9299,  0.2333,  1.6527],
        [ 0.2457,  0.0323,  0.2776],
        [-0.3951, -0.5277,  0.3975],
        [-0.2237, -0.3093,  0.9168],
        [ 0.0867, -1.4883,  1.4514],
        [-1.0499,  0.5372,  1.4842],
        [-0.1961, -0.2073,  1.3173],
        [-0.2303, -0.6174,  1.1624],
        [-0.5068, -0.2381,  1.2150],
        [ 0.3594, -1.7030,  1.0117],
        [ 0.3119, -0.6560, -0.3673],
        [-0.9048, -0.3577,  2.0727],
        [-0.6183,  0.6136,  0.1297],
        [-0.3179, -1.0454,  1.5431],
        [-0.4515, -0.3351,  0.2815],
        [ 1.0924, -1.1022, -0.6144],
        [-0.3104, -0.6608,  1.5319],
        [-0.7355, -0.3730,  1.3739],
        [ 0.2530, -1.3590,  1.1530],
        [ 0.8338, -0.7714,  0.5208],
        [-0.1832, -0.5352,  1.6597],
        [ 0.2288, -0.1552,  0.0520],
        [-1.1300,  0.9957,  0.7640],
        [-1.1812,  0.7236,  1.1442],
        [-1.4043,  1.3439,  0.9750],
        [-1.3408,  0.6924,  1.3095],
        [-1.0361,  0.5832,  1.2412],
        [-1.0531,  0.3936,  1.4199],
        [-1.2364,  0.6528,  1.1276],
        [-1.5648,  1.2771,  0.8824],
        [-1.1701,  1.0661,  1.2200],
        [-1.2888,  0.8366,  1.0872],
        [-1.1359,  0.4857,  1.3777],
        [-1.3078,  0.8667,  1.2092],
        [-1.3275,  1.0570,  1.0536],
        [-0.9693,  0.7567,  1.0468],
        [-1.2326,  0.9111,  1.1335],
        [-1.0694,  0.4442,  1.2533],
        [-1.0551,  1.1683,  1.1590],
        [-1.4836,  0.8106,  1.1767],
        [-1.2585,  0.8535,  1.5770],
        [-1.2683,  0.8799,  1.4923],
        [-1.0311,  0.7590,  1.3924],
        [-1.4029,  0.8495,  1.3247],
        [-1.2921,  1.1791,  1.2478],
        [-1.3453,  0.6237,  1.2891],
        [-1.2835,  0.9429,  1.0707],
        [-1.1127,  0.8008,  1.2368],
        [-1.3992,  1.1687,  0.9406],
        [-1.0449,  0.8250,  1.0479],
        [-1.1810,  1.0013,  0.8263],
        [-1.2383,  0.7642,  1.2811],
        [-1.2351,  0.7095,  1.2372],
        [-1.1194,  0.9284,  1.0202],
        [-1.3205,  1.0569,  0.7317],
        [-1.2329,  1.0034,  1.2041],
        [-1.3028,  1.0148,  1.5563],
        [-1.0766,  0.7526,  1.2164],
        [-1.4221,  1.1287,  1.1308],
        [-1.1776,  0.8473,  0.9060],
        [-1.0307,  0.5796,  1.3630],
        [-1.1283,  0.7122,  0.8948],
        [-1.3518,  0.9555,  1.2607],
        [-1.3164,  0.8649,  1.3218],
        [-1.3528,  1.1018,  0.8047],
        [-1.2436,  0.9465,  1.3641],
        [-1.2595,  1.1670,  0.8813],
        [-1.3602,  0.9748,  1.0964],
        [-1.3685,  1.2855,  1.0212],
        [-1.1556,  1.1803,  0.9676],
        [-1.3226,  0.5262,  1.4522],
        [-1.2973,  1.2219,  1.1482],
        [-1.5551,  0.9795,  1.1808],
        [-1.0460,  0.7830,  1.3380],
        [-1.0389,  0.7300,  0.8028],
        [-1.1503,  0.5141,  1.3412],
        [-1.1568,  0.5873,  1.0235],
        [-1.2145,  1.0827,  0.9745],
        [-1.0330,  0.6452,  1.2647],
        [-1.2094,  0.9365,  1.4144],
        [-1.1803,  0.8548,  0.9744],
        [-1.1227,  0.8641,  1.2736],
        [-0.9852,  0.8534,  1.2488],
        [-1.1759,  0.6863,  1.1620],
        [-1.1091,  0.7497,  1.4854],
        [-1.0574,  0.6447,  1.2199],
        [-1.1052,  0.7194,  0.9715],
        [-1.3083,  1.0050,  1.1190],
        [-1.1038,  0.8491,  1.1915],
        [-1.2598,  1.0488,  1.1950],
        [-1.2028,  1.1559,  1.1056]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)
Traceback (most recent call last):
  File "/home/nooman/Documents/Transformer-Training/training.py", line 23, in <module>
    setup_training(data_dir, config)
  File "/home/nooman/Documents/Transformer-Training/training.py", line 16, in setup_training
    trainer.train(train_loader, val_loader)
  File "/home/nooman/Documents/Transformer-Training/train.py", line 146, in train
    loss.backward()
AttributeError: 'NoneType' object has no attribute 'backward'
